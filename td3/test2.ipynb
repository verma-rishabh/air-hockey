{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gym\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import utils\n",
    "# import OurDDPG\n",
    "# import DDPG\n",
    "from air_hockey_challenge.framework.air_hockey_challenge_wrapper import AirHockeyChallengeWrapper\n",
    "from air_hockey_agent.agent_builder import build_agent\n",
    "from air_hockey_challenge.utils.kinematics import inverse_kinematics, jacobian, forward_kinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_rewards(base_env, state, action, next_state, absorbing):\n",
    "    print(base_env, state, action, next_state, absorbing)\n",
    "    print(base_env.info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = AirHockeyChallengeWrapper(env=\"7dof-hit\", interpolation_order=1, debug=True)\n",
    "policy = build_agent(env.env_info)\n",
    "# evaluations = eval_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'table': {'length': 1.948, 'width': 1.038, 'goal_width': 0.25},\n",
       " 'puck': {'radius': 0.03165},\n",
       " 'mallet': {'radius': 0.04815},\n",
       " 'n_agents': 2,\n",
       " 'robot': {'n_joints': 7,\n",
       "  'ee_desired_height': 0.1645,\n",
       "  'joint_vel_limit': array([[-1.48352986, -1.48352986, -1.74532925, -1.30899694, -2.26892803,\n",
       "          -2.35619449, -2.35619449],\n",
       "         [ 1.48352986,  1.48352986,  1.74532925,  1.30899694,  2.26892803,\n",
       "           2.35619449,  2.35619449]]),\n",
       "  'joint_acc_limit': array([[-14.83529864, -14.83529864, -17.45329252, -13.08996939,\n",
       "          -22.68928028, -23.5619449 , -23.5619449 ],\n",
       "         [ 14.83529864,  14.83529864,  17.45329252,  13.08996939,\n",
       "           22.68928028,  23.5619449 ,  23.5619449 ]]),\n",
       "  'base_frame': [array([[ 1.  ,  0.  ,  0.  , -1.51],\n",
       "          [ 0.  ,  1.  ,  0.  ,  0.  ],\n",
       "          [ 0.  ,  0.  ,  1.  , -0.1 ],\n",
       "          [ 0.  ,  0.  ,  0.  ,  1.  ]]),\n",
       "   array([[-1.  ,  0.  ,  0.  ,  1.51],\n",
       "          [ 0.  , -1.  ,  0.  ,  0.  ],\n",
       "          [ 0.  ,  0.  ,  1.  , -0.1 ],\n",
       "          [ 0.  ,  0.  ,  0.  ,  1.  ]])],\n",
       "  'universal_height': 0.0645,\n",
       "  'control_frequency': 50,\n",
       "  'joint_pos_limit': array([[-2.96706, -2.0944 , -2.96706, -2.0944 , -2.96706, -2.0944 ,\n",
       "          -3.05433],\n",
       "         [ 2.96706,  2.0944 ,  2.96706,  2.0944 ,  2.96706,  2.0944 ,\n",
       "           3.05433]]),\n",
       "  'robot_model': <mujoco._structs.MjModel at 0x7f1f0c7bad70>,\n",
       "  'robot_data': <mujoco._structs.MjData at 0x7f1e2298da70>},\n",
       " 'puck_pos_ids': [0, 1, 2],\n",
       " 'puck_vel_ids': [3, 4, 5],\n",
       " 'joint_pos_ids': [6, 7, 8, 9, 10, 11, 12],\n",
       " 'joint_vel_ids': [13, 14, 15, 16, 17, 18, 19],\n",
       " 'opponent_ee_ids': [20, 21, 22],\n",
       " 'dt': 0.02,\n",
       " 'rl_info': <mushroom_rl.core.environment.MDPInfo at 0x7f1f46ccb910>,\n",
       " 'constraints': <air_hockey_challenge.constraints.constraints.ConstraintList at 0x7f1f0c7b2850>,\n",
       " 'env_name': '7dof-hit'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.env_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mujoco._structs.MjModel at 0x7fdc36344570>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.robot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_anchor_pos(hit_pos_2d, hit_dir_2d, q_0):\n",
    "        hit_pos = np.concatenate([hit_pos_2d, [env.env_info['robot'][\"ee_desired_height\"]]])\n",
    "        hit_dir = np.concatenate([hit_dir_2d, [0]])\n",
    "        success, q_star = solve_hit_config(hit_pos, hit_dir, q_0)\n",
    "        print(success)\n",
    "        if not success:\n",
    "            q_star = q_0\n",
    "        return q_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_grad(fun, q):\n",
    "    eps = np.sqrt(np.finfo(np.float64).eps)\n",
    "    grad = np.zeros_like(q)\n",
    "    for i in range(q.shape[0]):\n",
    "        q_pos = q.copy()\n",
    "        q_neg = q.copy()\n",
    "        q_pos[i] += eps\n",
    "        q_neg[i] -= eps\n",
    "        grad[i] = (fun(q_pos, np.array([])) - fun(q_neg, np.array([]))) / 2 / eps\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlopt\n",
    "import numpy as np\n",
    "import osqp\n",
    "import scipy.linalg\n",
    "from scipy import sparse\n",
    "from air_hockey_challenge.utils.kinematics import inverse_kinematics, jacobian, forward_kinematics\n",
    "def solve_hit_config(x_des, v_des, q_0):\n",
    "        reg = 1e-6\n",
    "        dim = q_0.shape[0]\n",
    "        opt = nlopt.opt(nlopt.LD_SLSQP, dim)\n",
    "\n",
    "        def _nlopt_f(q, grad):\n",
    "            if grad.size > 0:\n",
    "                grad[...] = numerical_grad(_nlopt_f, q)\n",
    "            f = v_des @ jacobian(policy.robot_model, policy.robot_data, q)[:3, :dim]\n",
    "            return f @ f + reg * np.linalg.norm(q - q_0)\n",
    "\n",
    "        def _nlopt_h(q, grad):\n",
    "            if grad.size > 0:\n",
    "                grad[...] = 2 * (forward_kinematics(policy.robot_model, policy.robot_data, q)[0] - x_des) @ \\\n",
    "                            jacobian(policy.robot_model, policy.robot_data, q)[:3, :dim]\n",
    "            return np.linalg.norm(forward_kinematics(policy.robot_model, policy.robot_data, q)[0] - x_des) ** 2 - 1e-4\n",
    "\n",
    "        opt.set_max_objective(_nlopt_f)\n",
    "        opt.set_lower_bounds(policy.env_info['robot']['joint_pos_limit'][0])\n",
    "        opt.set_upper_bounds(policy.env_info['robot']['joint_pos_limit'][1])\n",
    "        opt.add_inequality_constraint(_nlopt_h)\n",
    "        opt.set_ftol_abs(1e-6)\n",
    "        opt.set_xtol_abs(1e-8)\n",
    "        opt.set_maxtime(5e-3)\n",
    "\n",
    "        success, x = inverse_kinematics(policy.robot_model, policy.robot_data, x_des, initial_q=q_0)\n",
    "        if not success:\n",
    "            raise NotImplementedError(\"Need to check\")\n",
    "        xopt = opt.optimize(x[:dim])\n",
    "        \n",
    "        return opt.last_optimize_result() > 0, xopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, done = env.reset(), False\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = build_agent(env.env_info) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[-5.44098112e-18 -1.54552975e-01 -5.01530089e-18 -1.83040804e+00\n",
      " -4.60353990e-18  9.17939732e-01  4.75070145e-21]\n"
     ]
    }
   ],
   "source": [
    "hit_pos_2d = np.array([ 6.800005e-01, -1.01327613e-38])\n",
    "x_curr = forward_kinematics(policy.robot_model, policy.robot_data, q_0)[0][:2]\n",
    "hit_dir_2d = (hit_pos_2d - x_curr)/0.02\n",
    "q_0 = policy.robot_data.qpos.copy()\n",
    "q = solve_anchor_pos(hit_pos_2d, hit_dir_2d, q_0)\n",
    "print(q)\n",
    "next_state, reward, done, info = env.step(q)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.50000005e-01 -1.01327613e-38  1.64500044e-01]\n"
     ]
    }
   ],
   "source": [
    "print(forward_kinematics(policy.robot_model, policy.robot_data, q_0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TD3_agent' object has no attribute 'n_joints'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/captain/mpc_rl project/air hockey/td3/test2.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/captain/mpc_rl%20project/air%20hockey/td3/test2.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m policy\u001b[39m.\u001b[39;49mn_joints\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TD3_agent' object has no attribute 'n_joints'"
     ]
    }
   ],
   "source": [
    "policy.n_joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _solve_aqp(x_des, q_cur, dq_anchor):\n",
    "        anchor_weights = np.array([10., 1., 10., 1., 10., 10., 1.])\n",
    "        x_cur = forward_kinematics(policy.robot_model, policy.robot_data, q_cur)[0]\n",
    "        jac = jacobian(policy.robot_model, policy.robot_data, q_cur)[:3, :policy.env_info['robot']['n_joints']]\n",
    "        N_J = scipy.linalg.null_space(jac)\n",
    "        b = np.linalg.lstsq(jac, (x_des - x_cur) / policy.env_info['dt'], rcond=None)[0]\n",
    "\n",
    "        P = (N_J.T @ np.diag(anchor_weights) @ N_J) / 2\n",
    "        q = (b - dq_anchor).T @ np.diag(anchor_weights) @ N_J\n",
    "        A = N_J.copy()\n",
    "        u = np.minimum(policy.env_info['robot']['joint_vel_limit'][1] * 0.9,\n",
    "                       (policy.env_info['robot']['joint_pos_limit'][1] * 0.92 - q_cur) / policy.env_info['dt']) - b\n",
    "        l = np.maximum(policy.env_info['robot']['joint_vel_limit'][0] * 0.9,\n",
    "                       (policy.env_info['robot']['joint_pos_limit'][0] * 0.92 - q_cur) / policy.env_info['dt']) - b\n",
    "\n",
    "        solver = osqp.OSQP()\n",
    "        solver.setup(P=sparse.csc_matrix(P), q=q, A=sparse.csc_matrix(A), l=l, u=u, verbose=False, polish=False)\n",
    "\n",
    "        result = solver.solve()\n",
    "        if result.info.status == 'solved':\n",
    "            return True, N_J @ result.x + b\n",
    "        else:\n",
    "            return False, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for @: 'csc_matrix' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/captain/mpc_rl project/air hockey/td3/test2.ipynb Cell 15\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/captain/mpc_rl%20project/air%20hockey/td3/test2.ipynb#X40sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m x_init\u001b[39m.\u001b[39mvalue \u001b[39m=\u001b[39m x0\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/captain/mpc_rl%20project/air%20hockey/td3/test2.ipynb#X40sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m prob\u001b[39m.\u001b[39msolve(solver\u001b[39m=\u001b[39mOSQP)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/captain/mpc_rl%20project/air%20hockey/td3/test2.ipynb#X40sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m x0 \u001b[39m=\u001b[39m Ad\u001b[39m@x0\u001b[39m \u001b[39m+\u001b[39m Bd\u001b[39m@u\u001b[39;49m[:,\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mvalue\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/captain/mpc_rl%20project/air%20hockey/td3/test2.ipynb#X40sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mprint\u001b[39m(x0)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for @: 'csc_matrix' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "from cvxpy import *\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "\n",
    "# Discrete time model of a quadcopter\n",
    "\n",
    "nx = 3\n",
    "nu = 7\n",
    "\n",
    "# Constraints\n",
    "u0 = 10.5916\n",
    "umin = env.env_info['robot']['joint_vel_limit'][0]\n",
    "umax = env.env_info['robot']['joint_vel_limit'][1]\n",
    "xmin = np.array([-.536,-.5,0.165])\n",
    "xmax = np.array([0,.5,0.17])\n",
    "\n",
    "# Objective function\n",
    "Q = sparse.diags([1.0,1.0,1.0])\n",
    "QN = Q\n",
    "R = 0.1*sparse.eye(7)\n",
    "\n",
    "# Initial and reference states\n",
    "x0 = np.array([-.536,-.5,0.16])\n",
    "xr = np.array([-.536,.5,0.16])\n",
    "\n",
    "# Prediction horizon\n",
    "N = 10\n",
    "\n",
    "# Define problem\n",
    "u = Variable((nu, N))\n",
    "x = Variable((nx, N+1))\n",
    "x_init = Parameter(nx)\n",
    "objective = 0\n",
    "constraints = [x[:,0] == x_init]\n",
    "\n",
    "Ad = sparse.diags([1.,1.,1.])\n",
    "q_0 = policy.robot_data.qpos.copy()\n",
    "Bd = sparse.csc_matrix(jacobian(policy.robot_model, policy.robot_data,q_0)[:3, :7]*env.env_info['dt'])\n",
    "\n",
    "for k in range(N):\n",
    "    objective += quad_form(x[:,k] - xr, Q) + quad_form(u[:,k], R)\n",
    "    constraints += [x[:,k+1] == Ad@x[:,k] + Bd@u[:,k]]\n",
    "    constraints += [xmin <= x[:,k], x[:,k] <= xmax]\n",
    "    constraints += [umin <= u[:,k], u[:,k] <= umax]\n",
    "objective += quad_form(x[:,N] - xr, QN)\n",
    "prob = Problem(Minimize(objective), constraints)\n",
    "\n",
    "# Simulate in closed loop\n",
    "nsim = 15\n",
    "for i in range(nsim):\n",
    "    x_init.value = x0\n",
    "    prob.solve(solver=OSQP)\n",
    "    x0 = Ad@x0 + Bd@u[:,0].value\n",
    "    print(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_trajectory(cart_traj, q_start, dq_start, q_anchor):\n",
    "        joint_trajectory = np.tile(np.concatenate([q_start]), (cart_traj.shape[0], 1))\n",
    "        if len(cart_traj) > 0:\n",
    "            q_cur = q_start.copy()\n",
    "            dq_cur = dq_start.copy()\n",
    "\n",
    "            for i, des_point in enumerate(cart_traj):\n",
    "                if q_anchor is None:\n",
    "                    dq_anchor = 0\n",
    "                else:\n",
    "                    dq_anchor = (q_anchor - q_cur)\n",
    "\n",
    "                success, dq_next = _solve_aqp(des_point[:3], q_cur, dq_anchor)\n",
    "\n",
    "                if not success:\n",
    "                    return success, []\n",
    "                else:\n",
    "                    q_cur += (dq_cur + dq_next) / 2 * policy.env_info['dt']\n",
    "                    # q_cur += dq_next * self.env_info['dt']\n",
    "                    dq_cur = dq_next\n",
    "                    joint_trajectory[i] = q_cur.copy()\n",
    "            return True, joint_trajectory\n",
    "        else:\n",
    "            return False, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.50000005e-01 -1.01327613e-38  1.64500044e-01]\n",
      "True [ 4.35637082e-11  1.33481178e+00 -2.74285594e-11  1.12376214e+00\n",
      " -2.16081042e-11 -1.35838313e-01 -1.62385446e-26]\n"
     ]
    }
   ],
   "source": [
    "# hit_pos = np.array([ 6.600005e-01, -1.01327613e-38,  1.64500044e-01])\n",
    "# print(forward_kinematics(policy.robot_model, policy.robot_data, q_0)[0])\n",
    "# q_0 = policy.robot_data.qpos.copy()\n",
    "# _,q = _solve_aqp(hit_pos, q_0,0)\n",
    "# q_cur += dq_next * policy.env_info['dt']\n",
    "# print(_,q)\n",
    "# next_state, reward, done, info = env.step(q)\n",
    "# env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "dq_start = np.array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.50000005e-01 -1.01327613e-38  1.64500044e-01]\n",
      "True [[-2.37163274e-05 -2.08884845e-01 -7.58625430e-05 -1.84406289e+00\n",
      "   4.35520934e-04  9.96416611e-01 -7.93374299e-06]]\n"
     ]
    }
   ],
   "source": [
    "hit_pos = np.array([ 6.3000005e-01, 3.01327613e-38,  1.64500044e-01])\n",
    "x_cur = forward_kinematics(policy.robot_model, policy.robot_data, q_0)[0]\n",
    "q_0 = policy.robot_data.qpos.copy()\n",
    "# _,q = _solve_aqp(hit_pos,q_0,0)\n",
    "cart_traj = np.array([hit_pos])\n",
    "q_start = q_0\n",
    "\n",
    "q_anchor = 0\n",
    "_,q = optimize_trajectory(cart_traj, q_start, dq_start, q_anchor)\n",
    "print(x_cur)\n",
    "print(_,q)\n",
    "next_state, reward, done, info = env.step(q[0])\n",
    "env.render()\n",
    "dq_start = next_state[13:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.39372151e-05, -1.80638512e-01, -1.02590470e-04, -1.84279688e+00,\n",
       "        4.83595636e-04,  9.50118644e-01, -1.71928170e-05])"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state[6:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.02979867e-22 -1.96067345e-01  2.56756848e-21 -1.84363898e+00\n",
      " -1.86530826e-21  9.70422238e-01  4.75070145e-21]\n"
     ]
    }
   ],
   "source": [
    "print(q_0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('challenge')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6100d8334917db35c4ec7cf716c3100bfc66eb35e85e153ba7e378d404aaa54d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
