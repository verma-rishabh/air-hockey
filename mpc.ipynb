{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T07:01:01.966877673Z",
     "start_time": "2023-11-17T07:00:57.602400688Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gym\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import utils\n",
    "# import OurDDPG\n",
    "# import DDPG\n",
    "from air_hockey_challenge.framework.air_hockey_challenge_wrapper import AirHockeyChallengeWrapper\n",
    "from air_hockey_agent.agent_builder_tqc import build_agent\n",
    "from air_hockey_challenge.utils.kinematics import inverse_kinematics, jacobian, forward_kinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T13:09:47.806346414Z",
     "start_time": "2023-11-03T13:09:47.801252160Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Runs policy for X episodes and returns average reward\n",
    "# # A fixed seed is used for the eval environment\n",
    "# def eval_policy(policy, eval_episodes=10):\n",
    "# \teval_env = AirHockeyChallengeWrapper(env=\"3dof-hit\", action_type=\"position-velocity\", interpolation_order=3, debug=True,custom_reward_function=custom_rewards)\n",
    "\n",
    "\n",
    "# \tavg_reward = 0.\n",
    "# \tfor _ in range(eval_episodes):\n",
    "# \t\tstate, done = eval_env.reset(), False\n",
    "# \t\twhile not done:\n",
    "# \t\t\taction = policy.draw_action(np.array(state)).reshape(2,3)\n",
    "# \t\t\tstate, reward, done, _ = eval_env.step(action)\n",
    "# \t\t\tavg_reward += reward\n",
    "\n",
    "# \tavg_reward /= eval_episodes\n",
    "\n",
    "# \tprint(\"---------------------------------------\")\n",
    "# \tprint(f\"Evaluation over {eval_episodes} episodes: {avg_reward:.3f}\")\n",
    "# \tprint(\"---------------------------------------\")\n",
    "# \treturn avg_reward\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T07:01:10.536325195Z",
     "start_time": "2023-11-17T07:01:06.202724001Z"
    }
   },
   "outputs": [],
   "source": [
    "env = AirHockeyChallengeWrapper(env=\"7dof-hit\", interpolation_order=1, debug=True)\n",
    "policy = build_agent(env.env_info)\n",
    "# evaluations = eval_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T07:04:02.350238974Z",
     "start_time": "2023-11-17T07:04:02.266431623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'table': {'length': 1.948, 'width': 1.038, 'goal_width': 0.25},\n 'puck': {'radius': 0.03165},\n 'mallet': {'radius': 0.04815},\n 'n_agents': 2,\n 'robot': {'n_joints': 7,\n  'ee_desired_height': 0.1645,\n  'joint_vel_limit': array([[-1.48352986, -1.48352986, -1.74532925, -1.30899694, -2.26892803,\n          -2.35619449, -2.35619449],\n         [ 1.48352986,  1.48352986,  1.74532925,  1.30899694,  2.26892803,\n           2.35619449,  2.35619449]]),\n  'joint_acc_limit': array([[-14.83529864, -14.83529864, -17.45329252, -13.08996939,\n          -22.68928028, -23.5619449 , -23.5619449 ],\n         [ 14.83529864,  14.83529864,  17.45329252,  13.08996939,\n           22.68928028,  23.5619449 ,  23.5619449 ]]),\n  'base_frame': [array([[ 1.  ,  0.  ,  0.  , -1.51],\n          [ 0.  ,  1.  ,  0.  ,  0.  ],\n          [ 0.  ,  0.  ,  1.  , -0.1 ],\n          [ 0.  ,  0.  ,  0.  ,  1.  ]]),\n   array([[-1.  ,  0.  ,  0.  ,  1.51],\n          [ 0.  , -1.  ,  0.  ,  0.  ],\n          [ 0.  ,  0.  ,  1.  , -0.1 ],\n          [ 0.  ,  0.  ,  0.  ,  1.  ]])],\n  'universal_height': 0.0645,\n  'control_frequency': 50,\n  'joint_pos_limit': array([[-2.96706, -2.0944 , -2.96706, -2.0944 , -2.96706, -2.0944 ,\n          -3.05433],\n         [ 2.96706,  2.0944 ,  2.96706,  2.0944 ,  2.96706,  2.0944 ,\n           3.05433]]),\n  'robot_model': <mujoco._structs.MjModel at 0x7f851777ccb0>,\n  'robot_data': <mujoco._structs.MjData at 0x7f851777ca30>},\n 'puck_pos_ids': [0, 1, 2],\n 'puck_vel_ids': [3, 4, 5],\n 'joint_pos_ids': [6, 7, 8, 9, 10, 11, 12],\n 'joint_vel_ids': [13, 14, 15, 16, 17, 18, 19],\n 'opponent_ee_ids': [20, 21, 22],\n 'dt': 0.02,\n 'rl_info': <mushroom_rl.core.environment.MDPInfo at 0x7f8517777460>,\n 'constraints': <air_hockey_challenge.constraints.constraints.ConstraintList at 0x7f8517777850>,\n 'env_name': '7dof-hit'}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "\n",
    "env_info = env.env_info\n",
    "\n",
    "q = obs[env_info['joint_pos_ids']]\n",
    "\n",
    "dq = obs[env_info['joint_vel_ids']]\n",
    "\n",
    "c_ee = env_info['constraints'].get('ee_constr').fun(q, dq)\n",
    "env_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T13:09:53.748108031Z",
     "start_time": "2023-11-03T13:09:53.486889352Z"
    }
   },
   "outputs": [],
   "source": [
    "# env = AirHockeyChallengeWrapper(env=\"3dof-hit\", action_type=\"position-velocity\", interpolation_order=3, debug=True)\n",
    "from air_hockey_challenge.utils.kinematics import forward_kinematics, jacobian\n",
    "state, done = env.reset(), False\n",
    "env.render()\n",
    "c_ee = env_info['constraints'].get('ee_constr').fun(q, dq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T13:10:01.327394956Z",
     "start_time": "2023-11-03T13:10:01.291909616Z"
    }
   },
   "outputs": [],
   "source": [
    "policy = build_agent(env.env_info) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T13:10:02.192676353Z",
     "start_time": "2023-11-03T13:10:02.055702483Z"
    }
   },
   "outputs": [],
   "source": [
    "from casadi import SX, sin, Function, inf,vertcat,nlpsol,qpsol,sumsqr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T13:10:03.037344557Z",
     "start_time": "2023-11-03T13:10:03.033123018Z"
    }
   },
   "outputs": [],
   "source": [
    "def integrate_RK4(s_expr, a_expr, sdot_expr, dt, N_steps=1):\n",
    "    '''RK4 integrator.\n",
    "\n",
    "    s_expr, a_expr: casadi expression that have been used to define the dynamics sdot_expr\n",
    "    sdot_expr:      casadi expr defining the rhs of the ode\n",
    "    dt:             integration interval\n",
    "    N_steps:        number of integration steps per integration interval, default:1\n",
    "    '''\n",
    "\n",
    "    h = dt/N_steps\n",
    "\n",
    "    s_end = s_expr\n",
    "\n",
    "    sdot_fun = Function('xdot', [s_expr, a_expr], [sdot_expr])\n",
    "\n",
    "    for _ in range(N_steps):\n",
    "\n",
    "    # FILL IN YOUR CODE HERE\n",
    "        v_1 = sdot_fun(s_end, a_expr)\n",
    "        v_2 = sdot_fun(s_end + 0.5 * h * v_1, a_expr)\n",
    "        v_3 = sdot_fun(s_end + 0.5 * h * v_2, a_expr)\n",
    "        v_4 = sdot_fun(s_end + v_3 * h, a_expr)\n",
    "        s_end += (1/6) * (v_1 + 2 * v_2 + 2 * v_3 + v_4) * h\n",
    "\n",
    "    F_expr = s_end\n",
    "\n",
    "    return F_expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T13:10:04.132958042Z",
     "start_time": "2023-11-03T13:10:04.123709431Z"
    }
   },
   "outputs": [],
   "source": [
    "def solve_casadi(x0_bar,x_des,jac):\n",
    "    # continuous model dynamics\n",
    "    n_s = 3  # number of states\n",
    "    n_a = 7  # number of actions\n",
    "\n",
    "    x = SX.sym('x')\n",
    "    y = SX.sym('y')\n",
    "    z = SX.sym('z')\n",
    "\n",
    "    omega = SX.sym('omega',7)\n",
    "\n",
    "    s = vertcat(x,y,z)\n",
    "    # q_0 = policy.robot_data.qpos.copy()\n",
    "    # jac = jacobian(policy.robot_model, policy.robot_data,q_0)[:3, :7]\n",
    "    s_dot = vertcat(jac @ omega)\n",
    "    # Define number of steps in the control horizon and discretization step\n",
    "    # print(s_dot)\n",
    "    N = 10\n",
    "    delta_t = 1/50\n",
    "    # Define RK4 integrator function and initial state x0_bar\n",
    "    F_rk4 = Function(\"F_rk4\", [s, omega], [integrate_RK4(s, omega, s_dot, delta_t)])\n",
    "    # x0_bar = [-.5, .5,.165]\n",
    "\n",
    "    # Define the weighting matrix for the cost function\n",
    "    Q = np.eye(n_s)\n",
    "    R = np.eye(n_a)\n",
    "\n",
    "        # Start with an empty NLP\n",
    "    w = []\n",
    "    w0 = []\n",
    "    lbw = []\n",
    "    ubw = []\n",
    "    J = 0\n",
    "    g = []\n",
    "    lbg = []\n",
    "    ubg = []\n",
    "\n",
    "    # \"Lift\" initial conditions\n",
    "    Xk = SX.sym('X0', 3)\n",
    "    w += [Xk]\n",
    "    lbw += x0_bar    # set initial state\n",
    "    ubw += x0_bar    # set initial state\n",
    "    w0 += x0_bar     # set initial state\n",
    "\n",
    "    # Formulate the NLP\n",
    "    for k in range(N):\n",
    "        # New NLP variable for the control\n",
    "        Uk = SX.sym('U_' + str(k),7)\n",
    "        w   += [Uk]\n",
    "        lbw += [-1.48352986, -1.48352986, -1.74532925, -1.30899694, -2.26892803,\n",
    "        -2.35619449, -2.35619449]\n",
    "        ubw += [1.48352986, 1.48352986, 1.74532925, 1.30899694, 2.26892803,\n",
    "        2.35619449, 2.35619449]\n",
    "        w0  += [0,0,0,0,0,0,0]\n",
    "\n",
    "        # Integrate till the end of the interval\n",
    "        Xk_end = F_rk4(Xk, Uk)\n",
    "        # J = J + delta_t *(sumsqr((Xk-x_des).T @ Q )+ sumsqr(R@Uk)) # Complete with the stage cost\n",
    "        J = J + (sumsqr((Xk-x_des))) # Complete with the stage cost\n",
    "\n",
    "        # New NLP variable for state at end of interval\n",
    "        Xk = SX.sym(f'X_{k+1}', 3)\n",
    "        w += [Xk]\n",
    "        lbw += [.5,-.5,0.165]\n",
    "        ubw += [1.5,.5,0.175]\n",
    "        w0 += [0, 0,0]\n",
    "\n",
    "        # Add equality constraint to \"close the gap\" for multiple shooting\n",
    "        g   += [Xk_end-Xk]\n",
    "        lbg += [0, 0,0]\n",
    "        ubg += [0, 0,0]\n",
    "    J = J + sumsqr((Xk-x_des)) # Complete with the terminal cost (NOTE it should be weighted by delta_t)\n",
    "\n",
    "    # Create an NLP solver\n",
    "    prob = {'f': J, 'x': vertcat(*w), 'g': vertcat(*g)}\n",
    "    solver = nlpsol('solver', 'ipopt', prob)\n",
    "\n",
    "    # Solve the NLP\n",
    "    sol = solver(x0=w0, lbx=lbw, ubx=ubw, lbg=lbg, ubg=ubg)\n",
    "    w_opt = sol['x'].full().flatten()\n",
    "    # return np.array([w_opt[3::10],w_opt[4::10],w_opt[5::10],w_opt[6::10],w_opt[7::10],w_opt[8::10],w_opt[9::10]])\n",
    "    \n",
    "    return np.array(w_opt[3:10]),solver.stats()['success']\n",
    "    # return solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T13:10:04.969956658Z",
     "start_time": "2023-11-03T13:10:04.890455659Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m state, done \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mreset(), \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/MPCRL_Project/air-hockey/mpc+tqc/air_hockey_challenge/framework/air_hockey_challenge_wrapper.py:82\u001B[0m, in \u001B[0;36mAirHockeyChallengeWrapper.render\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     81\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrender\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 82\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_env\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/mpcrl/lib/python3.8/site-packages/mushroom_rl/environments/mujoco.py:173\u001B[0m, in \u001B[0;36mMuJoCo.render\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_viewer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    171\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_viewer \u001B[38;5;241m=\u001B[39m MujocoGlfwViewer(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdt, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_viewer_params)\n\u001B[0;32m--> 173\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_viewer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/mpcrl/lib/python3.8/site-packages/mushroom_rl/utils/mujoco/viewer.py:147\u001B[0m, in \u001B[0;36mMujocoGlfwViewer.render\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_loop_count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdt \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time_per_render\n\u001B[1;32m    146\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_loop_count \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 147\u001B[0m     \u001B[43mrender_inner_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    148\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_loop_count \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/miniconda3/envs/mpcrl/lib/python3.8/site-packages/mushroom_rl/utils/mujoco/viewer.py:132\u001B[0m, in \u001B[0;36mMujocoGlfwViewer.render.<locals>.render_inner_loop\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m glfw\u001B[38;5;241m.\u001B[39mwindow_should_close(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_window):\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop()\n\u001B[0;32m--> 132\u001B[0m     \u001B[43mexit\u001B[49m(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time_per_render \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.9\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time_per_render \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m0.1\u001B[39m \u001B[38;5;241m*\u001B[39m (time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m render_start)\n\u001B[1;32m    135\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;124;03mif return_img:\u001B[39;00m\n\u001B[1;32m    137\u001B[0m \u001B[38;5;124;03m    mujoco.mjr_readPixels(self.rgb_buffer, None, self._viewport, self._context)\u001B[39;00m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;124;03m    return self.rgb_buffer\u001B[39;00m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "state, done = env.reset(), False\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T13:10:09.669094643Z",
     "start_time": "2023-11-03T13:10:09.650349973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6500000046784176, -1.100262712369661e-37, 0.164500043833406]\n"
     ]
    }
   ],
   "source": [
    "q_0 = state[6:13]\n",
    "jac = jacobian(policy.robot_model, policy.robot_data,q_0)[:3, :7]\n",
    "x0 = list(forward_kinematics(policy.robot_model, policy.robot_data, q_0)[0])\n",
    "# x0 = [ 6.50000005e-01, -1.01327613e-38,  1.64500044e-01]\n",
    "print(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6000000000000001"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cos(0.2*np.pi*-0/100-np.pi)+1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-03T13:10:17.219246205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6500000046784176, -1.100262712369661e-37, 0.164500043833406]\n",
      "[ 6.5000000e-01 -2.4492936e-17  1.6500000e-01]\n",
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit https://github.com/coin-or/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "This is Ipopt version 3.14.11, running with linear solver MUMPS 5.4.1.\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:      177\n",
      "Number of nonzeros in inequality constraint Jacobian.:        0\n",
      "Number of nonzeros in Lagrangian Hessian.............:       30\n",
      "\n",
      "Total number of variables............................:      100\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:      100\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:       30\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  1.9600038e-01 1.40e-01 3.31e-02  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1  1.4768437e-01 1.26e-01 2.03e+00  -1.0 2.79e+00    -  9.08e-02 1.01e-01f  1\n",
      "   2  8.2861989e-02 9.15e-02 1.42e+01  -1.0 5.88e-01    -  7.35e-01 2.73e-01f  1\n",
      "   3  1.7163685e-03 1.11e-16 7.83e+00  -1.0 4.12e-01    -  5.73e-01 1.00e+00f  1\n",
      "   4  7.0041678e-04 1.11e-16 3.55e-15  -1.0 4.93e-01    -  1.00e+00 1.00e+00f  1\n",
      "   5  6.9910722e-04 1.11e-16 4.66e-15  -2.5 2.99e-03    -  1.00e+00 1.00e+00f  1\n",
      "   6  2.9017069e-04 1.11e-16 3.87e-04  -3.8 1.51e-01    -  9.80e-01 1.00e+00f  1\n",
      "   7  1.9500128e-04 1.11e-16 5.90e-04  -5.7 2.34e-01    -  9.03e-01 1.00e+00f  1\n",
      "   8  5.5178306e-05 1.11e-16 7.55e-05  -5.7 9.17e-02    -  9.87e-01 1.00e+00f  1\n",
      "   9  1.8302671e-05 1.11e-16 1.05e-16  -5.7 8.23e-02    -  1.00e+00 1.00e+00f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  10  5.1766215e-06 1.11e-16 9.25e-05  -8.6 4.68e-02    -  9.31e-01 1.00e+00f  1\n",
      "  11  1.5636719e-06 1.11e-16 1.01e-16  -8.6 2.61e-02    -  1.00e+00 1.00e+00f  1\n",
      "  12  5.8454090e-07 1.11e-16 9.99e-17  -8.6 1.95e-02    -  1.00e+00 1.00e+00f  1\n",
      "  13  3.3991758e-07 1.11e-16 1.10e-16  -8.6 6.62e-03    -  1.00e+00 1.00e+00f  1\n",
      "  14  2.7478144e-07 1.23e-32 1.09e-16  -9.0 3.39e-03    -  1.00e+00 1.00e+00f  1\n",
      "\n",
      "Number of Iterations....: 14\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   2.7478144331796830e-07    2.7478144331796830e-07\n",
      "Dual infeasibility......:   1.0875536477656763e-16    1.0875536477656763e-16\n",
      "Constraint violation....:   1.2325951644078309e-32    1.2325951644078309e-32\n",
      "Variable bound violation:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   5.1533339232837839e-09    5.1533339232837839e-09\n",
      "Overall NLP error.......:   5.1533339232837839e-09    5.1533339232837839e-09\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 15\n",
      "Number of objective gradient evaluations             = 15\n",
      "Number of equality constraint evaluations            = 15\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 15\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 14\n",
      "Total seconds in IPOPT                               = 0.018\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "      solver  :   t_proc      (avg)   t_wall      (avg)    n_eval\n",
      "       nlp_f  | 600.00us ( 40.00us)  51.33us (  3.42us)        15\n",
      "       nlp_g  |   1.35ms ( 90.00us) 114.89us (  7.66us)        15\n",
      "  nlp_grad_f  | 918.00us ( 54.00us)  96.10us (  5.65us)        17\n",
      "  nlp_hess_l  | 817.00us ( 58.36us)  43.58us (  3.11us)        14\n",
      "   nlp_jac_g  |   1.24ms ( 77.31us) 119.85us (  7.49us)        16\n",
      "       total  | 198.97ms (198.97ms)  21.36ms ( 21.36ms)         1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X Error of failed request:  BadWindow (invalid Window parameter)\n",
      "  Major opcode of failed request:  3 (X_GetWindowAttributes)\n",
      "  Resource id in failed request:  0xffffffff\n",
      "  Serial number of failed request:  241\n",
      "  Current serial number in output stream:  242\n"
     ]
    }
   ],
   "source": [
    "for i in range(-100,100):\n",
    "    x_des = np.array([0.2*np.cos(np.pi*i/100),0.2*np.sin(np.pi*i/100),0.165]) + np.array([0.85,0,0])\n",
    "    jac = jacobian(policy.robot_model, policy.robot_data,q_0)[:3, :7]\n",
    "    x0 = list(forward_kinematics(policy.robot_model, policy.robot_data, q_0)[0])\n",
    "    # x0 = [ 6.50000005e-01, -1.01327613e-38,  1.64500044e-01]\n",
    "    print(x0)\n",
    "    # x_des = [1.2,0.02,0.165]    \n",
    "    print(x_des)\n",
    "    q,_ = solve_casadi(x0,x_des,jac)\n",
    "    # print(q)\n",
    "    next_q = q_0 + q*0.02\n",
    "    next_state, reward, done, info = env.step(next_q)\n",
    "    env.render()\n",
    "    q_0 = next_state[6:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jacobian' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m jac \u001B[38;5;241m=\u001B[39m \u001B[43mjacobian\u001B[49m(policy\u001B[38;5;241m.\u001B[39mrobot_model, policy\u001B[38;5;241m.\u001B[39mrobot_data,q_0)[:\u001B[38;5;241m3\u001B[39m, :\u001B[38;5;241m7\u001B[39m]\n\u001B[1;32m      2\u001B[0m x0 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(forward_kinematics(policy\u001B[38;5;241m.\u001B[39mrobot_model, policy\u001B[38;5;241m.\u001B[39mrobot_data, q_0)[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# x0 = [ 6.50000005e-01, -1.01327613e-38,  1.64500044e-01]\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'jacobian' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "jac = jacobian(policy.robot_model, policy.robot_data,q_0)[:3, :7]\n",
    "x0 = list(forward_kinematics(policy.robot_model, policy.robot_data, q_0)[0])\n",
    "# x0 = [ 6.50000005e-01, -1.01327613e-38,  1.64500044e-01]\n",
    "print(x0)\n",
    "x_des = [1.2,0.02,0.165]\n",
    "print(x_des)\n",
    "q,_ = solve_casadi(x0,x_des,jac)\n",
    "print(_)\n",
    "# print(q)\n",
    "# next_q = q_0 + q*0.02\n",
    "# next_state, reward, done, info = env.step(next_q)\n",
    "# env.render()\n",
    "# q_0 = next_state[6:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('challenge')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6100d8334917db35c4ec7cf716c3100bfc66eb35e85e153ba7e378d404aaa54d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
